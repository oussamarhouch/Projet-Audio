{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet simulation logicielle\n",
    "* *Rhouch Oussama*\n",
    "* *Cherki Inssaf*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure/model based.png\" alt=\"CS\" style=\"width: 750px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from scipy.io.wavfile import write\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing preprocessing on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unzip the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_paths = ['data/data_part1.zip', 'data/data_part2.zip', 'data/data_part3.zip', 'data/data_part4.zip']\n",
    "\n",
    "for zip_file_path in zip_file_paths:\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_folder = \"data/noise/\"\n",
    "clean_folder = \"data/clean/dev-clean\"\n",
    "output_folder = \"data/noisy/\"\n",
    "denoising_folder = \"data/denoising/\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "os.makedirs(denoising_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load clean audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of clean files\n",
    "clean_path = []\n",
    "for folder in os.listdir(clean_folder):\n",
    "    folder_path = os.path.join(clean_folder, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".flac\"):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    clean_path.append(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load noise audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of noise files\n",
    "noise_file = \"\"\n",
    "if os.path.isdir(noise_folder):\n",
    "        for root, dirs, files in os.walk(noise_folder):\n",
    "            for file in files:\n",
    "                if file.endswith(\".wav\"):\n",
    "                    noise_file = os.path.join(root, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RSB(clean, noisy):\n",
    "    clean = np.array(clean)\n",
    "    noisy = np.array(noisy)\n",
    "    return 10 * np.log10(np.sum(clean**2) / np.sum((clean - noisy)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(RSB):\n",
    "    return np.sqrt(10**(RSB/10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noisy(clean_file, noise_file, output_file):\n",
    "    s, sr = librosa.load(clean_file, sr=None)\n",
    "    u, sr = librosa.load(noise_file, sr=None)\n",
    "    \n",
    "    u = u[:len(s)]\n",
    "    \n",
    "    s_tf = np.fft.fft(s)\n",
    "    u_tf = np.fft.fft(u)\n",
    "    \n",
    "    RSB_value = RSB(s, u)\n",
    "    alpha_value = alpha(RSB_value)\n",
    "    \n",
    "    x_tf = s_tf + alpha_value * u_tf\n",
    "    \n",
    "    x = np.fft.ifft(x_tf)\n",
    "    \n",
    "    x = x.astype(np.float32)\n",
    "    \n",
    "    sf.write(output_file, x, sr)\n",
    "    \n",
    "    return x, s\n",
    "\n",
    "\n",
    "def load_audio(file_path):\n",
    "    audio, _ = librosa.load(file_path, sr=None)\n",
    "    return audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpeechDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        self.clean_files = []\n",
    "        self.noisy_files = []\n",
    "        self_original_length = []\n",
    "        self.i = 0\n",
    "        \n",
    "        for clean_file in clean_path:\n",
    "            output_path = f\"{output_folder}noisy_{self.i}.wav\"\n",
    "            x, s = make_noisy(clean_file, noise_file, output_path)\n",
    "            \n",
    "            self.clean_files.append(s)\n",
    "            self.noisy_files.append(x)\n",
    "            \n",
    "            self.i += 1\n",
    "            \n",
    "        for i in range(len(self.clean_files)):\n",
    "            s = self.clean_files[i]\n",
    "            x = self.noisy_files[i]\n",
    "            \n",
    "            self.clean_files[i] = torch.tensor(np.abs(np.fft.fft(s)))\n",
    "            self.noisy_files[i] = torch.tensor(np.abs(np.fft.fft(x)))\n",
    "            \n",
    "            self_original_length.append(len(s))\n",
    "                \n",
    "        self.max_len = max([len(s) for s in self.clean_files])\n",
    "        \n",
    "        for i in range(len(self.clean_files)):\n",
    "            self.clean_files[i] = F.pad(self.clean_files[i], (0, self.max_len - len(self.clean_files[i])))\n",
    "            self.noisy_files[i] = F.pad(self.noisy_files[i], (0, self.max_len - len(self.noisy_files[i])))\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.clean_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.noisy_files[idx], self.clean_files[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "dataset = SpeechDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = len(dataset.__getitem__(0)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save one of the clean and noisy in files from train_loader\n",
    "for i, (noisy, clean) in enumerate(train_loader):\n",
    "    noisy = noisy.squeeze(0).numpy()\n",
    "    clean = clean.squeeze(0).numpy()\n",
    "    \n",
    "    sf.write(f\"{denoising_folder}noisy.wav\", noisy, 16000)\n",
    "    sf.write(f\"{denoising_folder}clean.wav\", clean, 16000)\n",
    "    \n",
    "    if(i==1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
