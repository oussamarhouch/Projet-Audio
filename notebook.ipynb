{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet simulation logicielle\n",
    "* *Rhouch Oussama*\n",
    "* *Cherki Inssaf*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figure/model based.png\" alt=\"CS\" style=\"width: 750px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb=100\"\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performing preprocessing on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Unzip the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_file_paths = ['data/data_part1.zip', 'data/data_part2.zip', 'data/data_part3.zip', 'data/data_part4.zip']\n",
    "\n",
    "for zip_file_path in zip_file_paths:\n",
    "    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_folder = \"data/noise/\"\n",
    "clean_folder = \"data/clean/dev-clean\"\n",
    "output_folder = \"data/mixed\"\n",
    "\n",
    "# Create the output folder if it doesn't exist\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load clean audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of clean files\n",
    "clean_path = []\n",
    "for folder in os.listdir(clean_folder):\n",
    "    folder_path = os.path.join(clean_folder, folder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        for root, dirs, files in os.walk(folder_path):\n",
    "            for file in files:\n",
    "                if file.endswith(\".flac\"):\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    clean_path.append(file_path)\n",
    "\n",
    "clean_path[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load clean data\n",
    "s, s_rate = librosa.load(clean_path[0], sr=16000) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot clean audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "librosa.display.waveshow(s, sr=s_rate)\n",
    "plt.title('Clean Audio')\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fourier transform of clean audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the clean audio\n",
    "s_norm = preprocessing.normalize([s])\n",
    "\n",
    "# Fourier transform\n",
    "s_stft = librosa.stft(s_norm[0])\n",
    "\n",
    "# convert to dB\n",
    "s_stft_db = librosa.amplitude_to_db(abs(s_stft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot Fourier transform of clean audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the clean audio in frequency domain\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(s_stft_db, sr=s_rate, x_axis=\"time\", y_axis=\"hz\")\n",
    "plt.title(\"Clean audio in frequency domain\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noise audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load noise audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of noise files\n",
    "noise_file = \"\"\n",
    "if os.path.isdir(noise_folder):\n",
    "        for root, dirs, files in os.walk(noise_folder):\n",
    "            for file in files:\n",
    "                if file.endswith(\".wav\"):\n",
    "                    noise_file = os.path.join(root, file)\n",
    "\n",
    "noise_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load noise data\n",
    "u, u_rate = librosa.load(noise_file, sr=16000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot noise audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the noise audio\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(u, sr=u_rate)\n",
    "plt.title(\"Noise audio\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fourier transform of noise audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the clean audio\n",
    "u_norm = preprocessing.normalize([u[:len(s)]]) \n",
    "\n",
    "# Fourier transform\n",
    "u_stft = librosa.stft(u_norm[0])\n",
    "\n",
    "# convert to dB\n",
    "u_stft_db = librosa.amplitude_to_db(abs(u_stft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot Fourier transform of noise audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the noise audio in frequency domain\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(u_stft_db, sr=u_rate, x_axis=\"time\", y_axis=\"hz\")\n",
    "plt.title(\"Noise audio in frequency domain\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noisy audio data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### RSB: ratio signal to noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RSB\n",
    "rsb = 10 * np.log10(np.sum(s_stft**2)/np.sum(u_stft**2))\n",
    "rsb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### alpha: noise factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alpha\n",
    "alpha = 10**(-rsb/20)\n",
    "alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Noisy audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mix the clean and noise audio\n",
    "x = s_norm + alpha * u_norm\n",
    "x = x.astype(float)\n",
    "\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot noisy audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the noisy audio\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveshow(x, sr=s_rate)\n",
    "plt.title(\"Mixed audio\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fourier transform of noisy audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fourier transform of the noisy audio\n",
    "x_stft = librosa.stft(x[0])\n",
    "\n",
    "# convert to dB\n",
    "x_stft_db = librosa.amplitude_to_db(abs(x_stft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### plot Fourier transform of noisy audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the noisy audio in frequency domain\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.specshow(x_stft_db, sr=s_rate, x_axis=\"time\", y_axis=\"hz\")\n",
    "plt.title(\"Mixed audio in frequency domain\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, _ = librosa.magphase(u_stft)\n",
    "rms = librosa.feature.rms(S=U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14, 5), nrows=2, sharex=True)\n",
    "times = librosa.times_like(rms)\n",
    "ax[0].semilogy(times, rms[0], label='RMS Energy')\n",
    "ax[0].set(xticks=[], xlim=[times.min(), times.max()], ylabel='RMS Energy')\n",
    "ax[0].legend()\n",
    "ax[0].label_outer()\n",
    "librosa.display.specshow(librosa.amplitude_to_db(U), y_axis='log', x_axis='time', ax=ax[1])\n",
    "ax[1].set(title='log Power spectrogram')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_list = []\n",
    "s_rate_list = []\n",
    "for clean_data in clean_path:\n",
    "    s, s_rate = librosa.load(clean_path[0], sr=16000)\n",
    "    s_list.append(s)\n",
    "    s_rate_list.append(s_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing(Dataset):\n",
    "    def __init__(self, clean_path, noise_file):\n",
    "        self.clean_files = []\n",
    "        self.noisy_files = []\n",
    "        self.clean_path = clean_path\n",
    "        self.noise_file = noise_file\n",
    "        self.prepare_data()\n",
    "        self.adjust_length()\n",
    "\n",
    "    def mix(self, clean_audio_path, noise_file):\n",
    "        s, _ = librosa.load(clean_audio_path, sr=16000)\n",
    "        u_audio, _ = librosa.load(noise_file, sr=16000)\n",
    "\n",
    "        # Ensure the clean and noisy audio have the same length\n",
    "        min_length = min(len(s), len(u_audio))\n",
    "        s = s[:min_length]\n",
    "        u_audio = u_audio[:min_length]\n",
    "\n",
    "        s_norm = preprocessing.normalize([s])\n",
    "        u_norm = preprocessing.normalize([u_audio])\n",
    "        \n",
    "        s_stft = librosa.stft(s_norm[0])\n",
    "        u_stft = librosa.stft(u_norm[0])\n",
    "\n",
    "        rsb = 10 * np.log10(np.sum(s_stft**2) / np.sum(u_stft**2))\n",
    "        alpha = 10**(-rsb / 20)\n",
    "        x = s_norm + alpha * u_norm\n",
    "        \n",
    "        s_norm = torch.tensor(np.transpose(np.abs(librosa.stft(s_norm, n_fft=1024, hop_length=512)))).cuda()\n",
    "        x = torch.tensor(np.transpose(np.abs(librosa.stft(x, n_fft=1024, hop_length=512)))).cuda()\n",
    "\n",
    "        return s_norm, x\n",
    "\n",
    "    def prepare_data(self):\n",
    "        for clean_audio_path in self.clean_path:\n",
    "            clean, noisy = self.mix(clean_audio_path, self.noise_file)\n",
    "            self.clean_files.append(clean)\n",
    "            self.noisy_files.append(noisy)\n",
    "    \n",
    "    #adjust the length of the audio files\n",
    "    def adjust_length(self):\n",
    "        # Get the minimum shape of the clean audio files\n",
    "        pad_shape = min([file.shape[0] for file in self.clean_files])\n",
    "        for i in range(len(self.clean_files)):\n",
    "            diff_pad = pad_shape - self.clean_files[i].shape[0]\n",
    "            self.clean_files[i] = F.pad(self.clean_files[i], (0, 0, diff_pad, 0))\n",
    "            self.noisy_files[i] = F.pad(self.noisy_files[i], (0, 0, diff_pad, 0))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clean_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (torch.tensor(self.noisy_files[idx]), torch.tensor(self.clean_files[idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and test sets (80% training, 20% test)\n",
    "clean_train, clean_test = train_test_split(clean_path[:20], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Preprocessing object for the training set\n",
    "preprocessor_train = Preprocessing(clean_train, noise_file)\n",
    "\n",
    "# Create a Preprocessing object for the test set\n",
    "preprocessor_test = Preprocessing(clean_test, noise_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(preprocessor_train), len(preprocessor_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=preprocessor_train, batch_size=100, shuffle=True)\n",
    "test_loader = DataLoader(dataset=preprocessor_test, batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if train_loader have tensors of equal size\n",
    "for noisy, clean in train_loader:\n",
    "    print(noisy.shape)\n",
    "    print(clean.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network_1D, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=9, stride=1, padding=4)\n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=1, kernel_size=9, stride=1, padding=4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.sigmoid(self.conv3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_2D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network_2D, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=(9, 9), stride=1, padding=(4, 4))\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=(9, 9), stride=1, padding=(4, 4))\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=1, kernel_size=(9, 9), stride=1, padding=(4, 4))\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.sigmoid(self.conv3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(network_RNN, self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=1, hidden_size=64, num_layers=2, batch_first=True, bidirectional=True)\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x, _ = self.rnn(x)\n",
    "        x = self.sigmoid(self.fc(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train each model\n",
    "def train(model, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (noisy, clean) in enumerate(train_loader):\n",
    "        # Find the maximum size in the current batch\n",
    "        max_size = max(noisy.size(1), clean.size(1))\n",
    "        \n",
    "        # Pad the tensors to the maximum size\n",
    "        noisy = F.pad(noisy.unsqueeze(1), (0, max_size - noisy.size(1)))\n",
    "        clean = F.pad(clean.unsqueeze(1), (0, max_size - clean.size(1)))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(noisy)\n",
    "        loss = criterion(output, clean)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\t Average loss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(noisy), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for noisy, clean in test_loader:\n",
    "            noisy = noisy.unsqueeze(1)\n",
    "            clean = clean.unsqueeze(1)\n",
    "            output = model(noisy)\n",
    "            test_loss += criterion(output, clean).item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.6f}'.format(test_loss))\n",
    "    return test_loss\n",
    "\n",
    "def save_model(model, epoch, optimizer, loss, path):\n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss\n",
    "    }, path)\n",
    "    \n",
    "def load_model(model, optimizer, path):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch = checkpoint['epoch']\n",
    "    loss = checkpoint['loss']\n",
    "    return model, optimizer, epoch, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now train each model with data\n",
    "# 1D CNN\n",
    "model_1D = network_1D()\n",
    "optimizer_1D = optim.Adam(model_1D.parameters(), lr=0.001)\n",
    "criterion = nn.MSELoss()\n",
    "n_epochs = 10\n",
    "path = \"model_1D.pth\"\n",
    "train_loss_1D = []\n",
    "test_loss_1D = []\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(model_1D, train_loader, optimizer_1D, criterion, epoch)\n",
    "    train_loss_1D.append(test(model_1D, train_loader, criterion))\n",
    "    test_loss_1D.append(test(model_1D, test_loader, criterion))\n",
    "    save_model(model_1D, epoch, optimizer_1D, test_loss_1D[-1], path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2D CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
